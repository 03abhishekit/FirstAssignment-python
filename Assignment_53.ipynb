{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29494473-f162-4894-bcae-2dedbe048320",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?\n",
    "\n",
    "Answer :\n",
    "\n",
    "Overfitting: Overfitting occurs when a model learns the training data too well, capturing noise or random fluctuations in the data rather than the underlying pattern. Consequences include poor generalization to unseen data, high variance, and inaccurate predictions on new data. Overfitting can be mitigated by using techniques like cross-validation, regularization, reducing model complexity, and increasing the size of the training data.\n",
    "\n",
    "Underfitting: Underfitting occurs when a model is too simple to capture the underlying structure of the data. Consequences include poor performance on both training and test data, high bias, and an inability to capture complex patterns. Underfitting can be mitigated by increasing the complexity of the model, adding more features, or reducing regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81298ac2-5fae-4eb8-9d80-6416398147be",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "\n",
    "Answer:\n",
    "\n",
    "We can reduce overfitting by:\n",
    "Using simpler models with fewer parameters.\n",
    "Collecting more training data.\n",
    "Applying regularization techniques such as L1 or L2 regularization.\n",
    "Using techniques like dropout in neural networks.\n",
    "Performing feature selection or dimensionality reduction.\n",
    "Using cross-validation to tune hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e0657-ee77-4671-86c3-258a7ffced53",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Underfitting: Underfitting occurs when a model is too simple to capture the underlying structure of the data. It can occur when:\n",
    "The model is too simple relative to the complexity of the data.\n",
    "Insufficient features are used to describe the data.\n",
    "The model is under-trained due to limited training time or resources.\n",
    "The learning algorithm is not capable of capturing the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05cbe02-df3a-4403-a87b-df8499deebcf",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Bias-Variance Tradeoff: The bias-variance tradeoff is the balance between the error introduced by bias (the difference between the expected prediction of the model and the true value) and the error introduced by variance (the variability of the model's predictions for a given data point).\n",
    "\n",
    "Relationship: High bias models tend to underfit the data, while high variance models tend to overfit the data. Increasing model complexity reduces bias but increases variance, and vice versa. Finding the right balance between bias and variance is crucial for optimal model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91867371-0182-4d32-afd8-fe7cea9f5c03",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Methods for detecting overfitting and underfitting:\n",
    "\n",
    "Validation Curves: Plotting training and validation error as a function of model complexity.\n",
    "\n",
    "Learning Curves: Plotting training and validation error as a function of training data size.\n",
    "\n",
    "Cross-Validation: Splitting the data into multiple train-test splits and evaluating performance.\n",
    "\n",
    "Model Evaluation Metrics: Using metrics like accuracy, precision, recall, or F1-score to evaluate performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c922502-eab5-42e4-aa78-2c70b42f397b",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Bias: Bias measures how well a model fits the training data. High bias models have low complexity and tend to underfit the data. Examples include linear regression with few features.\n",
    "\n",
    "Variance: Variance measures how much the model's predictions vary for different training datasets. High variance models have high complexity and tend to overfit the data. Examples include decision trees with unlimited depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d76868-892f-4d5b-8866-53475a827e79",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Regularization: Regularization is a technique used to prevent overfitting by adding a penalty term to the model's loss function. Common techniques include:\n",
    "\n",
    "L1 Regularization (Lasso): Adds the absolute value of the coefficients as a penalty term.\n",
    "\n",
    "L2 Regularization (Ridge): Adds the squared value of the coefficients as a penalty term.\n",
    "\n",
    "Elastic Net Regularization: Combines L1 and L2 regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
