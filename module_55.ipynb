{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e6cab-aacd-494e-9771-c86931075b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: Filter Method in Feature Selection\n",
    "Definition:\n",
    "The Filter method for feature selection involves evaluating the relevance of features based on statistical measures \n",
    "without involving any machine learning algorithms. It ranks features by their correlation with the target variable.\n",
    "\n",
    "How it Works:\n",
    "    Compute statistical scores for each feature.\n",
    "    Rank features based on their scores.\n",
    "    Select the top-ranked features according to a pre-determined threshold or criteria.\n",
    "    \n",
    "    Common Techniques:\n",
    "        Pearson correlation coefficient\n",
    "        Chi-square test\n",
    "        ANOVA \n",
    "        F-test\n",
    "        Mutual Information\n",
    "        Example Code:\n",
    "            \n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Apply Chi-Square Filter Method\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Original features:\", X.columns)\n",
    "print(\"Selected features after Chi-Square:\", X.columns[chi2_selector.get_support()])\n",
    "\n",
    "\n",
    "Q2: Wrapper Method in Feature Selection\n",
    "Definition:\n",
    "The Wrapper method evaluates feature subsets by training a machine learning model and measuring its performance. \n",
    "It involves iterative selection and evaluation of feature subsets.\n",
    "Difference from Filter Method:Wrapper methods consider the interaction between features and the model,\n",
    "whereas Filter methods evaluate features independently of the model.\n",
    "Wrapper methods are generally more computationally intensive but can yield better results for model performance.\n",
    "Common Techniques:Recursive Feature Elimination (RFE)Forward SelectionBackward Elimination\n",
    "\n",
    "Example Code:\n",
    "    \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load dataset\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Apply RFE with RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "\n",
    "print(\"Original features:\", X.columns)\n",
    "print(\"Selected features after RFE:\", X.columns[rfe.support_])\n",
    "\n",
    "Q3: Embedded Feature Selection Methods\n",
    "\n",
    "Definition:\n",
    "Embedded methods perform feature selection during the model training process.\n",
    "These methods are built into the algorithms.\n",
    "Common Techniques:\n",
    "    Lasso Regression (L1 regularization)\n",
    "    Ridge Regression (L2 regularization)\n",
    "    Tree-based methods (e.g., Decision Trees, Random Forests)\n",
    "    Example Code:\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Apply Lasso for feature selection\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "importance = lasso.coef_\n",
    "\n",
    "print(\"Feature importances:\", importance)\n",
    "print(\"Selected features:\", X.columns[importance != 0])\n",
    "\n",
    "\n",
    "Q4: Drawbacks of Using the Filter Method\n",
    "Independence Assumption: Assumes features are independent of each other, which may not be true.\n",
    "Ignores Interaction: Does not consider feature interactions with the model.\n",
    "May Miss Important Features: May discard features that are weakly relevant on their own but important when combined with others.\n",
    "\n",
    "Q5: When to Prefer Filter Method Over Wrapper Method\n",
    "\n",
    "Large Datasets: When the dataset is large and computational efficiency is critical.\n",
    "Preliminary Feature Selection: As an initial step to narrow down the feature set before applying more complex methods.\n",
    "Simplicity and Speed: When a quick and simple method is needed to get a rough idea of important features.\n",
    "\n",
    "Q6: Using the Filter Method for Customer Churn Prediction in Telecom\n",
    "Steps:Load the Dataset: Import the dataset containing customer information and churn labels.\n",
    "Preprocess the Data: Handle missing values, encode categorical features, and scale numerical features.\n",
    "Apply Filter Method: Use statistical techniques to rank features based on their correlation with the target variable.\n",
    "Select Features: Choose the top-ranked features for the predictive model.\n",
    "\n",
    "Example Code:\n",
    "    \n",
    "# Example for a hypothetical dataset\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "# Assuming df is the DataFrame containing the telecom customer data\n",
    "# and 'Churn' is the target variable\n",
    "df = pd.read_csv('telecom_customer_data.csv')\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# Apply Mutual Information Filter Method\n",
    "mi_selector = SelectKBest(mutual_info_classif, k=10)\n",
    "X_kbest = mi_selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected features:\", X.columns[mi_selector.get_support()])\n",
    "\n",
    "\n",
    "Q7: Using Embedded Method for Soccer Match Outcome Prediction\n",
    "\n",
    "Steps:Load the Dataset: Import the dataset containing player statistics and team rankings.\n",
    "Preprocess the Data: Handle missing values, encode categorical features, and scale numerical features.\n",
    "Apply Embedded Method: Train a model with built-in feature selection, such as Lasso or a tree-based model.\n",
    "Extract Important Features: Identify and select the most relevant features based on the models coefficients or feature importances.\n",
    "Example Code:\n",
    "    \n",
    "from sklearn.linear_model import Lasso\n",
    "# Load and preprocess the dataset\n",
    "# Assuming df is the DataFrame containing the soccer match data\n",
    "# and 'Outcome' is the target variable\n",
    "df = pd.read_csv('soccer_match_data.csv')\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Apply Lasso for feature selection\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "importance = lasso.coef_\n",
    "\n",
    "print(\"Selected features:\", X.columns[importance != 0])\n",
    "\n",
    "Q8: Using Wrapper Method for House Price Prediction\n",
    "\n",
    "Steps:Load the Dataset: Import the dataset containing house features and prices.\n",
    "Preprocess the Data: Handle missing values, encode categorical features, and scale numerical features.\n",
    "Apply Wrapper Method: Use RFE or another wrapper method to iteratively select the best subset of features.\n",
    "Train and Evaluate Model: Train the model with the selected features and evaluate its performance.\n",
    "\n",
    "Example Code:\n",
    "    \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "# Assuming df is the DataFrame containing the house data\n",
    "# and 'Price' is the target variable\n",
    "df = pd.read_csv('house_data.csv')\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# Apply RFE with LinearRegression\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected features:\", X.columns[rfe.support_])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
